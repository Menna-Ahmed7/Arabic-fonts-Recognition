{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join, dirname, exists\n",
    "from PIL import Image\n",
    "import os\n",
    "# from sklearn.svm import SVC\n",
    "from scipy.signal import convolve2d\n",
    "# from sklearn.externals import joblib\n",
    "# import joblib\n",
    "import matplotlib.pyplot as pyplot\n",
    "import pickle\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=pickle.load(\"Logistic Regression.pkl\")\n",
    "with open('Logistic Regression.pkl', 'rb') as file:\n",
    "    # Deserialize and load the object from the file\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rotate the image with given theta value\n",
    "def rotate(img, theta):\n",
    "    rows, cols = img.shape[0], img.shape[1]\n",
    "    image_center = (cols/2, rows/2)\n",
    "    \n",
    "    M = cv2.getRotationMatrix2D(image_center,theta,1)\n",
    "\n",
    "    abs_cos = abs(M[0,0])\n",
    "    abs_sin = abs(M[0,1])\n",
    "\n",
    "    bound_w = int(rows * abs_sin + cols * abs_cos)\n",
    "    bound_h = int(rows * abs_cos + cols * abs_sin)\n",
    "\n",
    "    M[0, 2] += bound_w/2 - image_center[0]\n",
    "    M[1, 2] += bound_h/2 - image_center[1]\n",
    "\n",
    "    # rotate orignal image to show transformation\n",
    "    rotated = cv2.warpAffine(img,M,(bound_w,bound_h),borderValue=(int(img[0][0]),int(img[0][0]),int(img[0][0])))\n",
    "    return rotated\n",
    "def round_to_angle_multiples(number):\n",
    "\n",
    "    # Define the possible angles\n",
    "    angles = [45, -45, 90, -90, 135, -135]\n",
    "\n",
    "    # Calculate the absolute difference between the number and each angle\n",
    "    differences = [abs(number - angle) for angle in angles]\n",
    "\n",
    "    # Find the index of the angle with the smallest difference\n",
    "    min_index = differences.index(min(differences))\n",
    "\n",
    "    # Return the corresponding angle\n",
    "    return angles[min_index]\n",
    "\n",
    "\n",
    "def rotate_img(edgeimage,originalimage):\n",
    "    # Apply Hough Lines Transform\n",
    "    lines = cv2.HoughLinesP(edgeimage, rho=1, theta=np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)\n",
    "    \n",
    "    finalImage=originalimage\n",
    "    # Find the longest line\n",
    "    longest_line = None\n",
    "    max_length = 0\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            # Calculate line length using distance formula\n",
    "            length = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "            if length > max_length:\n",
    "                max_length = length\n",
    "                longest_line = line\n",
    "\n",
    "        if longest_line is not None:\n",
    "            x1, y1, x2, y2 = longest_line[0]\n",
    "            if x2 - x1 != 0:  # Avoid division by zero\n",
    "                 orientation = np.arctan((y2 - y1) / (x2 - x1))*180  # Radians\n",
    "            else:\n",
    "                orientation = 180/2  # Vertical line (slope is undefined)\n",
    "            # print(\"oo\",orientation)\n",
    "            if (orientation>20.0 or orientation<-20):\n",
    "                orientation=round_to_angle_multiples(orientation)\n",
    "                finalImage = rotate(originalimage, 180-orientation)\n",
    "        \n",
    "        # # print(orientation)\n",
    "        # # Draw only the longest line (if any)\n",
    "        # if longest_line is not None:\n",
    "        #     x1, y1, x2, y2 = longest_line[0]\n",
    "        #     cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 2)  # Draw blue line with thickness 2\n",
    "        #     display(img,\"box\")\n",
    "\n",
    "    return finalImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Salt and pepper noise\n",
    "    img=cv2.medianBlur(img,5)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # display(img)\n",
    "\n",
    "    # cv2.imshow('Detected Lines (Longest)', img)\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(img, 20, 150)  # Adjust threshold values as needed\n",
    "\n",
    "    rotated_img=rotate_img(edges,img)\n",
    "    # display(img)\n",
    "    if (img[0][0]>200):\n",
    "        _, img = cv2.threshold(rotated_img, 50.0, 255.0, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "    else:\n",
    "        _, img = cv2.threshold(rotated_img, 50.0, 255.0, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    # display(img)\n",
    "    return img\n",
    "\n",
    "def process_image(image_path, output_dir):\n",
    "    img = preprocess(image_path)  # Assuming preprocess returns a NumPy array\n",
    "    img = Image.fromarray(img)  # Convert to PIL Image object\n",
    "    new_path = join(output_dir, image_path.split(\"/\")[-1])\n",
    "    img.save(new_path)\n",
    "    \n",
    "def process_folder(folder_path):\n",
    "    for folder in listdir(folder_path):\n",
    "        img = join(folder_path, folder)\n",
    "        if isfile(img) and img.lower().endswith(\".jpeg\"):\n",
    "        # Check for image files with common extensions\n",
    "            process_image(img, \"Processed-fonts-dataset\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpq(img_filepath, winSize=3,freqestim=1,mode='h'):\n",
    "\n",
    "\timg = cv2.imread(img_filepath,0)\n",
    "\trho=0.90\n",
    "\n",
    "\tSTFTalpha=1/winSize  # alpha in STFT approaches (for Gaussian derivative alpha=1)\n",
    "\tsigmaS=(winSize-1)/4 # Sigma for STFT Gaussian window (applied if freqestim==2)\n",
    "\tsigmaA=8/(winSize-1) # Sigma for Gaussian derivative quadrature filters (applied if freqestim==3)\n",
    "\n",
    "\tconvmode='valid' # Compute descriptor responses only on part that have full neigborhood. Use 'same' if all pixels are included (extrapolates np.image with zeros).\n",
    "\n",
    "\timg=np.float64(img) # Convert np.image to double\n",
    "\tr=(winSize-1)/2 # Get radius from window size\n",
    "\tx=np.arange(-r,r+1)[np.newaxis] # Form spatial coordinates in window\n",
    "\n",
    "\tif freqestim==1:  #  STFT uniform window\n",
    "\t    #  Basic STFT filters\n",
    "\t\t\tw0=np.ones_like(x)\n",
    "\t\t\tw1=np.exp(-2*np.pi*x*STFTalpha*1j)\n",
    "\t\t\tw2=np.conj(w1)\n",
    "\n",
    "\t## Run filters to compute the frequency response in the four points. Store np.real and np.imaginary parts separately\n",
    "\t# Run first filters\n",
    "\tfilterResp1=convolve2d(convolve2d(img,w0.T,convmode),w1,convmode)\n",
    "\tfilterResp2=convolve2d(convolve2d(img,w1.T,convmode),w0,convmode)\n",
    "\tfilterResp3=convolve2d(convolve2d(img,w1.T,convmode),w1,convmode)\n",
    "\tfilterResp4=convolve2d(convolve2d(img,w1.T,convmode),w2,convmode)\n",
    "\n",
    "\t# Initilize frequency domain matrix for four frequency coordinates (np.real and np.imaginary parts for each frequency).\n",
    "\tfreqResp=np.dstack([filterResp1.real, filterResp1.imag,\n",
    "\t                    filterResp2.real, filterResp2.imag,\n",
    "\t                    filterResp3.real, filterResp3.imag,\n",
    "\t                    filterResp4.real, filterResp4.imag])\n",
    "\n",
    "\t## Perform quantization and compute LPQ codewords\n",
    "\tinds = np.arange(freqResp.shape[2])[np.newaxis,np.newaxis,:]\n",
    "\tLPQdesc=((freqResp>0)*(2**inds)).sum(2)\n",
    "\n",
    "\t## Histogram if needed\n",
    "\tif mode=='nh' or mode=='h':\n",
    "\t    LPQdesc=np.histogram(LPQdesc.flatten(),range(256))[0]\n",
    "\n",
    "\t## Normalize histogram if needed\n",
    "\tif mode=='nh':\n",
    "\t    LPQdesc=LPQdesc/LPQdesc.sum()\n",
    "\n",
    "\t# print (LPQdesc)\n",
    "\tLPQdesc = np.array(LPQdesc)\n",
    "\treturn LPQdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_features=[]\n",
    "# image_predictions={}\n",
    "# image_time={}\n",
    "\n",
    "# for folder in os.listdir(\"test\"):\n",
    "#     img = os.path.join(\"test\", folder)\n",
    "#     if isfile(img) and img.lower().endswith(\".jpeg\"):\n",
    "#         start_time = time.time()\n",
    "#         process_image(img,\"Processed-test\")\n",
    "#         path=\"Processed-test/test/\"+folder\n",
    "#         # print(path)\n",
    "#         imageLPQ = lpq(path)  # Assuming lpq is defined elsewhere\n",
    "#         # print(imageLPQ)\n",
    "#         label=model.predict(np.array([imageLPQ]))\n",
    "#         end_time_prediction = time.time() \n",
    "#         image_predictions[int(folder[:-5])]=label\n",
    "#         image_time[int(folder[:-5])]=round(end_time_prediction-start_time,3)\n",
    "#         # print(model.predict(np.array([imageLPQ])),\"\\n\")\n",
    "\n",
    "#     # break\n",
    "#         # print(f\"Processed image: {img}\")\n",
    "#         # print(\"-----------------------------------\")\n",
    "\n",
    "# sorted_predictions = dict(sorted(image_predictions.items(), key=lambda item: item[0]))\n",
    "# output_text = \"\"\n",
    "# for img_name, prediction in sorted_predictions.items():\n",
    "#   output_text += f\"{prediction[0]}\\n\"\n",
    "\n",
    "# with open(\"results.txt\", \"w\") as output_file:\n",
    "#   output_file.write(output_text)\n",
    "\n",
    "# sorted_time = dict(sorted(image_time.items(), key=lambda item: item[0]))\n",
    "# output_time = \"\"\n",
    "# for img_name, time in sorted_time.items():\n",
    "#   output_time += f\"{time[0]}\\n\"\n",
    "\n",
    "# with open(\"time.txt\", \"w\") as output_file:\n",
    "#   output_file.write(output_time)\n",
    "\n",
    "# # for filename in os.listdir(\"Processed-test/test\"):\n",
    "# #     if filename.endswith(\".jpeg\"):\n",
    "# #         image_path = os.path.join(filename, filename)\n",
    "# #         print(image_path)\n",
    "\n",
    "# # test_features=np.array(test_features)\n",
    "# # print(test_features.shape)\n",
    "\n",
    "# # labels=model.predict(test_features)\n",
    "# # print(labels)\n",
    "# # for i, label in enumerate(labels):\n",
    "# #     print(f\"Image {i + 1} has label: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
